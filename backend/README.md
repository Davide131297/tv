````markdown
# TV Politik Dashboard - Backend

Automatisiertes Web-Crawling-System fÃ¼r deutsche Talkshows mit Zeitsteuerung und API-Endpunkten.

## ğŸ¯ Zweck

Dieses Backend crawlt automatisch die Mediatheken deutscher Politik-Talkshows und extrahiert Politiker-Auftritte:

- **Markus Lanz** (ZDF)
- **Maybrit Illner** (ZDF)
- **Caren Miosga** (ARD)
- **Maischberger** (ARD)
- **Hart aber fair** (ARD)

## ğŸ“ Projektstruktur

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.ts                   # Express Server & Cron Jobs
â”‚   â”œâ”€â”€ supabase.ts             # Supabase Client Konfiguration
â”‚   â”œâ”€â”€ crawler/                # Web-Crawler fÃ¼r jede Show
â”‚   â”‚   â”œâ”€â”€ haf.ts              # Hart aber Fair
â”‚   â”‚   â”œâ”€â”€ illner.ts           # Maybrit Illner
â”‚   â”‚   â”œâ”€â”€ lanz.ts             # Markus Lanz
â”‚   â”‚   â”œâ”€â”€ maischberger.ts     # Maischberger
â”‚   â”‚   â””â”€â”€ miosga.ts           # Caren Miosga
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ browser-configs.ts   # Puppeteer Konfiguration
â”‚   â”‚   â””â”€â”€ utils.ts            # Utility-Funktionen & DB-Operationen
â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ abgeordnetenwatch.ts # TypeScript Definitionen
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## âš™ï¸ Installation

1. Repository klonen und AbhÃ¤ngigkeiten installieren:

```bash
cd backend
npm install
```

2. Umgebungsvariablen konfigurieren (`.env`):

```env
# Supabase
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_supabase_key

# Optional: Port
PORT=9000
```

## ğŸš€ Entwicklung

```bash
# Development Server mit Hot-Reload
npm run dev

# TypeScript kompilieren
npm run build

# Production Server
npm run start
```

Der Server lÃ¤uft standardmÃ¤ÃŸig auf `http://localhost:9000`

## â° Automatische Crawling-ZeitplÃ¤ne

Das System lÃ¤uft automatische Cron-Jobs:

- **Lanz**: Mittwoch, Donnerstag, Freitag um 2:00 Uhr
- **Hart aber Fair**: Dienstag um 1:00 Uhr
- **Illner**: Freitag um 2:00 Uhr
- **Maischberger**: Mittwoch, Donnerstag um 2:00 Uhr
- **Miosga**: Montag um 1:00 Uhr

## ğŸ”— API Endpunkte

### Manuelle Crawler-Trigger

```bash
# Einzelne Crawler manuell starten
POST /api/crawl-lanz          # Markus Lanz
POST /api/crawl-haf           # Hart aber Fair
POST /api/crawl-illner        # Maybrit Illner
POST /api/crawl-maischberger  # Maischberger
POST /api/crawl-miosga        # Caren Miosga

# Health Check
GET /                         # "Hello World!"
```

### Beispiel-Aufruf

```bash
curl -X POST http://localhost:9000/api/crawl-lanz
```

## ğŸ› ï¸ Technologie-Stack

- **Express.js** - Web-Framework
- **TypeScript** - Typsicherheit
- **Puppeteer** - Browser-Automatisierung fÃ¼r Web-Scraping
- **Node-Cron** - Zeitgesteuerte Aufgaben
- **Supabase** - Cloud-Datenbank (PostgreSQL)
- **Axios** - HTTP-Client fÃ¼r APIs
- **Cheerio** - Server-seitiges HTML-Parsing
- **Pino** - Strukturiertes Logging

## ğŸ”„ Crawling-Prozess

1. **Mediathek-Navigation**: Puppeteer Ã¶ffnet Show-Ãœbersichtsseiten
2. **Episode-Extraktion**: Sammelt Links zu neuen Episoden
3. **GÃ¤ste-Analyse**: Extrahiert GÃ¤ste-Namen aus Beschreibungen
4. **Politiker-Validierung**: Abgleich mit abgeordnetenwatch.de API
5. **Datenbank-Speicherung**: Validierte Daten â†’ Supabase
6. **Themen-Klassifikation**: KI-gestÃ¼tzte politische Themen-Analyse

## ğŸ—ƒï¸ Datenbank-Schema

Das Backend arbeitet mit folgenden Supabase-Tabellen:

- `tv_show_politicians` - Politiker-Auftritte
- `show_links` - Episode-URLs
- `political_areas` - Themen-Kategorien
- `episode_political_areas` - Episode-Themen-Zuordnung

## ğŸ”§ Konfiguration

### Browser-Setup (Puppeteer)

```typescript
// Optimierte Konfiguration fÃ¼r Server-Umgebungen
const browser = await puppeteer.launch({
  headless: true,
  args: ["--no-sandbox", "--disable-setuid-sandbox", "--disable-dev-shm-usage"],
});
```

### Crawler-Fehlerbehandlung

- Automatische Wiederholungen bei Netzwerkfehlern
- Rate-Limiting fÃ¼r API-Aufrufe
- Graceful Degradation bei Parser-Problemen
- AusfÃ¼hrliche Logging fÃ¼r Debugging

## ğŸ› Troubleshooting

### HÃ¤ufige Probleme:

**Puppeteer startet nicht:**

```bash
# Linux: Chrome-AbhÃ¤ngigkeiten installieren
sudo apt-get install -y gconf-service libasound2 libatk1.0-0 libcairo2

# macOS: Keine zusÃ¤tzlichen Schritte nÃ¶tig
# Windows: Stelle sicher, dass Visual C++ Redistributable installiert ist
```

**Supabase-Verbindungsfehler:**

- PrÃ¼fe `SUPABASE_URL` und `SUPABASE_ANON_KEY`
- ÃœberprÃ¼fe Supabase RLS-Policies
- Kontrolliere Netzwerk-/Firewall-Einstellungen

**Crawler findet keine Daten:**

- Websites kÃ¶nnen Layout-Ã„nderungen haben
- PrÃ¼fe Browser-Logs in der Konsole
- Teste manuell mit `npm run dev` und einzelnen Endpunkten

## ğŸ“Š Monitoring & Logs

```bash
# Live-Logs anzeigen
npm run dev

# Crawler-Status prÃ¼fen
curl http://localhost:9000/

# Einzelnen Crawler testen
curl -X POST http://localhost:9000/api/crawl-lanz
```

## ğŸ“ Logs & Debugging

Das System verwendet strukturiertes Logging:

```bash
# Beispiel-Log-Ausgabe
2025-10-18T10:00:00.000Z INFO: Starte Lanz Crawl...
2025-10-18T10:01:23.456Z INFO: Episode gefunden: 2025-10-17
2025-10-18T10:01:45.789Z INFO: âœ… Politiker: Angela Merkel (CDU)
2025-10-18T10:02:00.000Z INFO: Lanz Crawl abgeschlossen.
```

## ğŸ” Sicherheit

- Keine API-Keys in Repository committet
- Rate-Limiting fÃ¼r externe APIs
- Input-Sanitization fÃ¼r alle Crawler-Daten
- Sichere Supabase RLS-Policies

## ğŸ“„ Lizenz

MIT License - siehe Frontend fÃ¼r Details.

---

FÃ¼r Frontend-Integration siehe [../frontend/README.md](../frontend/README.md)
````
