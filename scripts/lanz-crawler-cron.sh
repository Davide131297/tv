#!/bin/bash

# Markus Lanz Crawler Cron Job
# LÃ¤uft jeden Mittwoch, Donnerstag und Freitag um 1:00 Uhr nachts

# Script-Verzeichnis ermitteln
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"

# Wechsle ins Backend-Verzeichnis
cd "$PROJECT_DIR/backend" || {
    echo "âŒ Fehler: Backend-Verzeichnis nicht gefunden: $PROJECT_DIR/backend"
    exit 1
}

# Log-Datei mit Datum
LOG_DATE=$(date +"%Y-%m-%d_%H-%M-%S")
LOG_FILE="$PROJECT_DIR/logs/lanz-crawler-$LOG_DATE.log"

# Erstelle Logs-Verzeichnis falls es nicht existiert
mkdir -p "$PROJECT_DIR/logs"

# Funktion fÃ¼r strukturiertes Logging
log() {
    local level="$1"
    shift
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [$level] $*" | tee -a "$LOG_FILE"
}

# Script starten
log "INFO" "ğŸš€ Starte Markus Lanz Crawler Cron Job"
log "INFO" "ğŸ“ Arbeitsverzeichnis: $(pwd)"
log "INFO" "ğŸ“ Log-Datei: $LOG_FILE"

# Node.js Version prÃ¼fen
if command -v node &> /dev/null; then
    NODE_VERSION=$(node --version)
    log "INFO" "ğŸ“¦ Node.js Version: $NODE_VERSION"
else
    log "ERROR" "âŒ Node.js nicht gefunden!"
    exit 1
fi

# NPX verfÃ¼gbar?
if command -v npx &> /dev/null; then
    log "INFO" "âœ… NPX verfÃ¼gbar"
else
    log "ERROR" "âŒ NPX nicht gefunden!"
    exit 1
fi

# PrÃ¼fe ob TypeScript-Datei existiert
CRAWLER_FILE="src/crawler/lanz-incremental.ts"
if [[ ! -f "$CRAWLER_FILE" ]]; then
    log "ERROR" "âŒ Crawler-Datei nicht gefunden: $CRAWLER_FILE"
    exit 1
fi

# Starte den inkrementellen Crawler
log "INFO" "ğŸ¬ Starte inkrementellen Markus Lanz Crawler..."

if npx ts-node "$CRAWLER_FILE" >> "$LOG_FILE" 2>&1; then
    log "INFO" "âœ… Crawler erfolgreich abgeschlossen"
    
    # Zeige Zusammenfassung aus dem Log
    if grep -q "Episoden verarbeitet:" "$LOG_FILE"; then
        EPISODES_PROCESSED=$(grep "Episoden verarbeitet:" "$LOG_FILE" | tail -1 | sed 's/.*Episoden verarbeitet: //')
        POLITICIANS_INSERTED=$(grep "Politiker eingefÃ¼gt:" "$LOG_FILE" | tail -1 | sed 's/.*Politiker eingefÃ¼gt: //')
        
        log "INFO" "ğŸ“Š Zusammenfassung: $EPISODES_PROCESSED Episoden, $POLITICIANS_INSERTED Politiker"
        
        # Bei neuen Episoden: Notification senden (optional)
        if [[ "$EPISODES_PROCESSED" -gt 0 ]]; then
            log "INFO" "ğŸ†• Neue Episoden gefunden! Episoden: $EPISODES_PROCESSED, Politiker: $POLITICIANS_INSERTED"
            
            # Hier kÃ¶nnte man zusÃ¤tzlich eine E-Mail oder Slack-Notification senden
            # curl -X POST -H 'Content-type: application/json' \
            #   --data '{"text":"ğŸ¬ Neue Markus Lanz Episode: '"$EPISODES_PROCESSED"' Episoden, '"$POLITICIANS_INSERTED"' Politiker gefunden!"}' \
            #   $SLACK_WEBHOOK_URL
        fi
    fi
    
    # Cleanup: Behalte nur die letzten 30 Log-Dateien
    find "$PROJECT_DIR/logs" -name "lanz-crawler-*.log" -type f -mtime +30 -delete 2>/dev/null || true
    
    exit 0
else
    log "ERROR" "âŒ Crawler ist fehlgeschlagen"
    
    # Bei Fehler: letzte Zeilen des Logs zeigen
    log "ERROR" "ğŸ“‹ Letzte Log-EintrÃ¤ge:"
    tail -10 "$LOG_FILE" | while read line; do
        log "ERROR" "   $line"
    done
    
    exit 1
fi